{% extends "base.html" %}

{% block title %}
about codesear.ch
{% end %}

{% block body %}
    <div class="about">
      This is an implementation of &ldquo;fgrep&rdquo; running on a
      single &ldquo;small&rdquo; EC2 instance. It's indexing all of
      the C source and header files in the Linux 3.4.4 kernel (more
      than 14,000,000 lines of code, including all drivers, auxilliary
      code, tools, etc.).
      <p>
      The basic idea for this implementation is inspired
      by <a href="http://swtch.com/~rsc/regexp/regexp4.html">http://swtch.com/~rsc/regexp/regexp4.html</a>,
      although this implementation is more limited (it does not
      support regexes). Regex support should be coming real soon
      though.
      <h2>Implementation Notes &amp; Buzzwords</h2>
      The implementation uses a custom
      <a href="http://www.igvita.com/2012/02/06/sstable-and-log-structured-storage-leveldb/">SSTable</a>
      implementation written in C++,
      using <a href="https://developers.google.com/protocol-buffers/docs/overview">Protocol
      Buffers</a>. The search index is mmap'ed, but not otherwise
      loaded into memory; likewise, there is no caching done on any
      queries (other than the usual page caching that happens on
      Linux). The search index is heavily sharded and multi-threaded,
      using C++11 threads. The sharding logic is mostly what allows
      the backend to return so quickly (i.e. the multi-threading
      doesn't help on this EC2 instance, since small instances only
      have one CPU). The sharding level is fairly high (right now,
      there are about 80 total shards), so generally the speedup on a
      multi-core system would be about proportional to the number of
      cores on that system. On my dual-core consumer grade laptop,
      even pathological queries generally return in under 50
      milliseconds.
      <p>
      The frontend is written in Python
      (using <a href="http://www.tornadoweb.org/">tornado</a>), and
      communicates to the backend using a custom asynchronous RPC
      protocol. The protocol is based around Protocol Buffers. The
      client uses tornado async capabilites and the backend is written
      using <a href="http://www.boost.org/libs/asio">boost::asio</a>. For
      fun I made the entire frontend run asynchronously using
      tornado's <a href="http://www.tornadoweb.org/documentation/web.html#tornado.web.asynchronous">asynchronous</a>
      decorator, which means that a single frontend process/thread can
      service multiple requests simultaneously, if it's blocked on the
      backend.
      <p>
      The search index and the RPC protocol both use Google's
      excellent <a href="http://code.google.com/p/snappy/">Snappy</a>
      library for compression.
      <p>
      The poorly written Javascript code works
      using <a href="http://zeptojs.com/">Zepto</a>
      + <a href="https://github.com/janl/mustache.js/">Mustache.js</a>.
    </div>
{% end %}
